{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75829ccb",
   "metadata": {},
   "source": [
    "# Polish\n",
    "\n",
    "## prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21dc043c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "你是一名阿拉伯语专家，我将向你提供一段阿拉伯语报纸文本，其中可能存在较多缺漏、错误。\n",
      "你的工作是在尽可能保持原意的基础上修正，将缺失的内容补全、错误的内容修正、清除可能的乱码。\n",
      "\n",
      "注意一定要保持原文意思。\n",
      "\n",
      "你的回复应当遵守以下格式，在此之外不要有其它的陈述：\n",
      "“修正后的内容为：（在这里写入你的修正结果）”\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "system_prompt = '''\n",
    "你是一名阿拉伯语专家，我将向你提供一段阿拉伯语报纸文本，其中可能存在较多缺漏、错误。\n",
    "你的工作是在尽可能保持原意的基础上修正，将缺失的内容补全、错误的内容修正、清除可能的乱码。\n",
    "\n",
    "注意一定要保持原文意思。\n",
    "\n",
    "你的回复应当遵守以下格式，在此之外不要有其它的陈述：\n",
    "“修正后的内容为：（在这里写入你的修正结果）”\n",
    "\n",
    "'''\n",
    "\n",
    "print(system_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b9b509",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e90ac16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to C:\\Users\\黄柏喻\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cdd66dc543a4cf69cadbbb8da3f1b3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/280 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\黄柏喻\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3251de3010a44610aed12e765e06b2bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/8.93M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32078fc1fa264cfebb6e19e3ba2750d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/26489 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "from huggingface_hub import login\n",
    "\n",
    "# 输入你的 Hugging Face API token\n",
    "login('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')\n",
    "\n",
    "ds = load_dataset(\"Adelante/revolution-only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "110d4286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['context'],\n",
       "        num_rows: 26489\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed676f9a",
   "metadata": {},
   "source": [
    "## API\n",
    "\n",
    "Only small batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31b49ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import asyncio\n",
    "from datasets import load_dataset\n",
    "import json\n",
    "import openai\n",
    "from tqdm.asyncio import tqdm\n",
    "\n",
    "# 加载数据集\n",
    "dataset = ds['train']['context']\n",
    "\n",
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "974db507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "# take several to try\n",
    "\n",
    "small_batch = dataset[::1000]\n",
    "print(len(small_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98ba81e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def async_query_openai(query_message):\n",
    "    from openai import AsyncOpenAI\n",
    "    client = AsyncOpenAI(\n",
    "        base_url=\"https://api.siliconflow.cn/v1/\",\n",
    "        api_key=\"sk-qejjytxlxmlphjxvqbogoqduoswphdeuowgnakyhuqxkjffr\"\n",
    "    )\n",
    "\n",
    "    \n",
    "    response = await client.chat.completions.create(\n",
    "        model=\"deepseek-ai/DeepSeek-V2-Chat\",\n",
    "        messages=[\n",
    "            {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": query_message # 输入给他的东西\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=4096,\n",
    "        temperature=0.01,\n",
    "        # 下面的都是默认参数没动过\n",
    "        top_p=0.7,\n",
    "        # top_k=50,\n",
    "        frequency_penalty=1,\n",
    "        # stop=[\"<|eot_id|>\"],\n",
    "        stream=False\n",
    "    \n",
    "    )\n",
    "\n",
    "    if not response:\n",
    "        return 'null'\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "\n",
    "# 处理单个文本的函数\n",
    "async def process_text(text):\n",
    "    prompt = system_prompt + text\n",
    "    return await async_query_openai(prompt)\n",
    "\n",
    "# 将结果写入 .jsonl 文件的函数\n",
    "def write_results_to_jsonl(rawtexts, results, filename):\n",
    "    with open(filename, 'a', encoding='utf-8') as f:  # 注意改为'a'模式，追加到文件中\n",
    "        for raw, result in zip(rawtexts, results):\n",
    "            entry = {\n",
    "                \"origin\":raw,\n",
    "                \"response\": result\n",
    "            }\n",
    "            json.dump(entry, f, ensure_ascii=False)\n",
    "            f.write('\\n')\n",
    "\n",
    "# 主函数，运行 asyncio 事件循环和写入结果\n",
    "async def main():\n",
    "    import nest_asyncio\n",
    "    nest_asyncio.apply()\n",
    "    batch_size = 10\n",
    "    for i in tqdm(range(0, len(small_batch), batch_size)):\n",
    "        current_batch = small_batch[i:i+batch_size]\n",
    "        print(f\"Processing batch {i // batch_size + 1}...\")\n",
    "        results = await process_all_texts(current_batch)\n",
    "        write_results_to_jsonl(current_batch, results, 'results.jsonl')\n",
    "        print(f\"Batch {i // batch_size + 1} written to results.jsonl\")\n",
    "        \n",
    "\n",
    "# 处理所有文本的函数，调整为处理一批文本\n",
    "async def process_all_texts(onebatch):\n",
    "    semaphore = asyncio.Semaphore(1000)\n",
    "    async def process_one_text(text):\n",
    "        async with semaphore:\n",
    "            return await process_text(text)\n",
    "    \n",
    "    tasks = []\n",
    "    for idx in range(len(onebatch)):\n",
    "        text = \"所提供给你的阿拉伯语报纸文本是：\\n\"+onebatch[idx]\n",
    "        tasks.append(process_one_text(text))\n",
    "    results = await asyncio.gather(*tasks)  # 使用 gather 等待所有任务完成并保持顺序\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce134b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|████████████████████████████                                                        | 1/3 [01:24<02:49, 84.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 written to results.jsonl\n",
      "Processing batch 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|████████████████████████████████████████████████████████                            | 2/3 [02:46<01:22, 82.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2 written to results.jsonl\n",
      "Processing batch 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [03:55<00:00, 78.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3 written to results.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f260329",
   "metadata": {},
   "source": [
    "## Check result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec336410",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    " \n",
    "file_jsonl_path = \"results.jsonl\"\n",
    "\n",
    "extract_results = []\n",
    "\n",
    "with open(file_jsonl_path, encoding='utf-8') as file:\n",
    "    for onetest in jsonlines.Reader(file):\n",
    "        extract_results.append(onetest['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "df1cb5a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'المحاضرة اعتزازية كرة الخارجية مالتعان مع الكية\\nالحربية باعتبارها إحدى المؤسسات الوطنية العريقة\\nوأضاف المتحدث أن عمرو أشار أيضا إلى تحرك\\nوزارة الخارجية في تعزيز روابط مصر مع فرنسا\\nالأفريقية. حيث زار بصفته أثيوبيا فور توليه منصبه\\nوزير الخارجية. كما سيزور السودان مطلع الشهر\\nالمقبل. مما يشير إلى قيامه بجولة في دول الحوض النيلي. ثم\\nيختتم شهر يناير بحضور القمة الأفريقية في\\nأبيدجان ويعكس هذا الحرص الأفريقي المكنس ما توليه\\nمصر من أهمية خاصة للبعد الأفريقي في سياستها\\nالخارجية. خاصة على ضوء، ما فرصته الثورة المصرية\\nمن مراجعة شاملة وإعادة ترتيب لأولويات المصالح\\nالمصرية والخارجية للبلاد. مشددا على أن\\nاهتمام مصر بدول الحوض النيلي لا يصدر عن اضطرار\\nبل عن اختيار بأن العلاقات الوثيقة مع هذه الدول هي\\nواقع ملازم التاريخ قبل أن نفرغه الجغرافيا\\nوالعربيا نباول نرى الخارجية دورا مسؤولا في التوسع\\nإلى حل سلمي للأزمة السورية عن طريق المبادرة\\nالعربية والحيلولة دون التدخل الأجنبي- وكذلك جهد\\nمصر لمعاوضة الأضرار، في ليبيا على إرساء الاستقرار\\nوإعادة بناء مؤسسات الدولة في المجالات المختلفة وفقا\\nللأولويات التي يحددونها هم'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 去除中文分割词\n",
    "takeaway_zh = [item.split(\"：\")[-1][1:] for item in extract_results]\n",
    "\n",
    "takeaway_zh[26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bdd55f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(small_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da32ee89",
   "metadata": {},
   "source": [
    "## Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d8366dbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6984b0e2cd4f4ce59ef3ae8a99809a56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "540b3a4cce8f461aa91a130b7ad4f4fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/Adelante/small_batch_of_polishing/commit/c69e9d4361598d0d2807c2200ec7fbbfeb6f9e18', commit_message='Upload dataset', commit_description='', oid='c69e9d4361598d0d2807c2200ec7fbbfeb6f9e18', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_batch_dataset = Dataset.from_dict({\"raw\":small_batch, \"polish\":takeaway_zh})\n",
    "\n",
    "small_batch_dataset.push_to_hub('small_batch_of_polishing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e987f078",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
