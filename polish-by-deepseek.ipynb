{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75829ccb",
   "metadata": {},
   "source": [
    "# Polish\n",
    "\n",
    "## prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21dc043c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "你是一名阿拉伯语专家，我将向你提供一段阿拉伯语报纸文本，其中可能存在较多缺漏、错误。\n",
      "你的工作是在尽可能保持原意的基础上修正，将缺失的内容补全、错误的内容修正、清除可能的乱码。\n",
      "\n",
      "注意：\n",
      "- 这段文本由OCR识别得到，所以你应该首先考虑字形识别的错误，以及由于图片模糊导致的文字缺失。\n",
      "- 一定要保持原文意思。\n",
      "- 尽可能把文本还原成语法正确、语义完整、通顺、符合逻辑的阿拉伯语报纸文本。\n",
      "\n",
      "你的回复应当遵守以下格式，在此之外不要有其它的陈述：\n",
      "“修正后的内容为：（在这里写入你的修正结果）”\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "system_prompt = '''\n",
    "你是一名阿拉伯语专家，我将向你提供一段阿拉伯语报纸文本，其中可能存在较多缺漏、错误。\n",
    "你的工作是在尽可能保持原意的基础上修正，将缺失的内容补全、错误的内容修正、清除可能的乱码。\n",
    "\n",
    "注意：\n",
    "- 这段文本由OCR识别得到，所以你应该首先考虑字形识别的错误，以及由于图片模糊导致的文字缺失。\n",
    "- 一定要保持原文意思。\n",
    "- 尽可能把文本还原成语法正确、语义完整、通顺、符合逻辑的阿拉伯语报纸文本。\n",
    "\n",
    "你的回复应当遵守以下格式，在此之外不要有其它的陈述：\n",
    "“修正后的内容为：（在这里写入你的修正结果）”\n",
    "\n",
    "'''\n",
    "\n",
    "print(system_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b9b509",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e90ac16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to C:\\Users\\Chen Qun\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (C:/Users/Chen Qun/.cache/huggingface/datasets/Adelante___parquet/Adelante--revolution-as-kw-date-and-containing-shorter-b9a09bfebdb5e2dc/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4efef5fffa14303aed095270303cf9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "from huggingface_hub import login\n",
    "\n",
    "# 输入你的 Hugging Face API token\n",
    "login('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')\n",
    "\n",
    "ds = load_dataset(\"Adelante/revolution-as-kw-date-and-containing-shorter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "110d4286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e47601c3dbb3482cb26ee0d3cbe24ac1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/48099 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['year', 'month', 'date', 'page', 'slice', 'text', 'containing'],\n",
       "        num_rows: 16203\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.filter(lambda x:len(x['containing'])>=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed676f9a",
   "metadata": {},
   "source": [
    "## API\n",
    "\n",
    "Only small batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31b49ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['year', 'month', 'date', 'page', 'slice', 'text', 'containing'],\n",
       "    num_rows: 48099\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import asyncio\n",
    "from datasets import load_dataset\n",
    "import json\n",
    "import openai\n",
    "from tqdm.asyncio import tqdm\n",
    "\n",
    "# 加载数据集\n",
    "dataset = ds['train']\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "974db507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# take several to try\n",
    "\n",
    "batch = [dataset[idx] for idx in range(len(dataset))]\n",
    "small_batch = batch[:1000]\n",
    "print(type(small_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98ba81e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def async_query_openai(query_message):\n",
    "    from openai import AsyncOpenAI\n",
    "    client = AsyncOpenAI(\n",
    "        base_url=\"https://api.siliconflow.cn/v1/\",\n",
    "        api_key=\"sk-xkucgdnxoclxsihlntfibegmmnoscfxpmiuypycbfnttbpvr\"\n",
    "    )\n",
    "\n",
    "    \n",
    "    response = await client.chat.completions.create(\n",
    "        model=\"deepseek-ai/DeepSeek-V2-Chat\",\n",
    "        messages=[\n",
    "            {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": query_message # 输入给他的东西\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=4096,\n",
    "        temperature=0.01,\n",
    "        # 下面的都是默认参数没动过\n",
    "        top_p=0.7,\n",
    "        # top_k=50,\n",
    "        frequency_penalty=1,\n",
    "        # stop=[\"<|eot_id|>\"],\n",
    "        stream=False\n",
    "    \n",
    "    )\n",
    "\n",
    "    if not response:\n",
    "        return 'null'\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "\n",
    "# 处理单个文本的函数\n",
    "async def process_text(text):\n",
    "    prompt = system_prompt + text\n",
    "    return await async_query_openai(prompt)\n",
    "\n",
    "# 将结果写入 .jsonl 文件的函数\n",
    "def write_results_to_jsonl(rawtexts, results, filename):\n",
    "    with open(filename, 'a', encoding='utf-8') as f:  # 注意改为'a'模式，追加到文件中\n",
    "        for raw, result in zip(rawtexts, results):\n",
    "            entry = {\n",
    "                \"origin\":raw,\n",
    "                \"response\": result\n",
    "            }\n",
    "            json.dump(entry, f, ensure_ascii=False)\n",
    "            f.write('\\n')\n",
    "\n",
    "# 主函数，运行 asyncio 事件循环和写入结果\n",
    "async def main():\n",
    "    import nest_asyncio\n",
    "    nest_asyncio.apply()\n",
    "    batch_size = 100\n",
    "    for i in tqdm(range(0, len(small_batch), batch_size)):\n",
    "        current_batch = small_batch[i:i+batch_size]\n",
    "        print(f\"Processing batch {i // batch_size + 1}...\")\n",
    "        results = await process_all_texts(current_batch)\n",
    "        write_results_to_jsonl(current_batch, results, 'results.jsonl')\n",
    "        print(f\"Batch {i // batch_size + 1} written to results.jsonl\")\n",
    "        \n",
    "\n",
    "# 处理所有文本的函数，调整为处理一批文本\n",
    "async def process_all_texts(onebatch):\n",
    "    semaphore = asyncio.Semaphore(10000)\n",
    "    async def process_one_text(text):\n",
    "        async with semaphore:\n",
    "            return await process_text(text)\n",
    "    \n",
    "    tasks = []\n",
    "    for idx in range(len(onebatch)):\n",
    "        text = \"所提供给你的阿拉伯语报纸文本是：\\n\"+onebatch[idx]['text']\n",
    "        tasks.append(process_one_text(text))\n",
    "    results = await asyncio.gather(*tasks)  # 使用 gather 等待所有任务完成并保持顺序\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce134b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [10:04<1:30:40, 604.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 written to results.jsonl\n",
      "Processing batch 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [18:58<1:15:06, 563.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2 written to results.jsonl\n",
      "Processing batch 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [29:01<1:07:49, 581.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3 written to results.jsonl\n",
      "Processing batch 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [35:08<49:40, 496.74s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4 written to results.jsonl\n",
      "Processing batch 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [38:56<33:19, 399.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5 written to results.jsonl\n",
      "Processing batch 6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [45:46<26:52, 403.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6 written to results.jsonl\n",
      "Processing batch 7...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [49:29<17:12, 344.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7 written to results.jsonl\n",
      "Processing batch 8...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [55:31<11:39, 349.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 8 written to results.jsonl\n",
      "Processing batch 9...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [1:05:31<07:08, 428.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 9 written to results.jsonl\n",
      "Processing batch 10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [1:14:44<00:00, 448.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 10 written to results.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f260329",
   "metadata": {},
   "source": [
    "## Check result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec336410",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    " \n",
    "file_jsonl_path = \"results.jsonl\"\n",
    "\n",
    "extract_results = []\n",
    "\n",
    "with open(file_jsonl_path, encoding='utf-8') as file:\n",
    "    for onetest in jsonlines.Reader(file):\n",
    "        extract_results.append(onetest['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df1cb5a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ءدسا١٧صبل٢٠١١\\nهفي اساهره\\nخداعال۵تد\\nكان خداع الذات هن اكهر\\nافات العظام السياسى الذى\\nذهب؛ فلم يكن يستمع لمن\\nبنكره مما وعد. ولم بش عفى\\nاستعداد لمعرفة حغمغة ها\\nالت إليه الامور. ولكن يعدو\\nأن خداع الذات واحدة من\\nالافات المصرية النى تدرس\\nلى فصول الثقافة السياسية.\\nوتنكرت الامر كله لعدما\\nساهمت المرامح النلبفزيوهبة\\nالنى راحت نحلل ما جرى عى\\nمماراة بادى الرمالك ونادى\\nالافرض التوسى\\nوعمدما قال الغانل إهها\\nمسالة سياسيان *بامتياز،\\nالركت امدى أمام كلام جاد،\\nولكر عسا جرى الامتعاد من\\nالموجز إفى التفاصيل ألركت\\nأن الآفة متاصلة.\\nفالحتدقة لم أكر اعرف\\nموحود الحرب الوطدى\\nحدى الان. وكل ما كان\\nمعرونا هو أن ،فلولا, له\\nنددعى استئصالها ولش ما ؛.\\nحد كان اب الحرد المهروم لم\\nصاحد١ -ئفدود- كزن كنه ؛\\nمدتعيا إفى مادى الزمالك، ا\\nوفبه من الاعداد ما يكنى أ\\n؛مذلاء تف د الغاهرذ-لكى ة\\nتخرج مدها البورة المضادة\\nالنى ابدفعت لكى نجهز ؛\\nعيي وحد؛ الثورتكل المصرمة ؛\\nوالتولسية.\\nلم بدخل فى الموسوع ان 1\\nالثورة ظلت ثورن فى ميدان ؟\\nالتحرير، وما معاكما كان ا\\nالسعى على نغالددد الشانعة ,ا\\nولم يكن سهلا أن بعقد ؛؛\\nالرما لك الدورى ومن معدد اً\\nالنخول فى الانوار التالمة ؛\\nبورى ألطال إبريقيا؛ ونى إ\\nا-و اخر لنى لغغد العرص النى [\\nلاحت مالعيات المادى للمادى\\nبلائيى٤دى مادى الرمالو إ\\nر\\nتمعلى الى متمادات عير ؛\\nمامومة.. والامر بى المهابة إ\\nشانع فى المماريات المصربة ؛\\nمع دول أو أمدبة سمال\\nإبربغدا. كاد دلك أيام المطام إ\\nاًلمائد وجدذأيخبذا فى1يام\\nالثورة المداركة الدى مضع خ\\nامصارها على كاهلها ١كثر ها ؛\\nمحنملود حاصة لو اقتصر ؛\\nالهم على مطاردة -فلول- ؛\\n* ٠أ\\nواسوالدىلممهاحم,دى ؛;\\nالارلفى ا لتوسى هغطدلكل\\nالمؤسسات العامة فى مصر.\\nلل إله احرق لورا كاملا فى\\nمؤسسة مهمتها ا لاسا سبة\\nمحاربة الفساد. ابها السادن ج\\nلا نصعوا الرؤوس فى\\nالرمال ؛\\nد- عبدالمنعم سعيد\\nج6. ؛؛1٢1.0٢ا3ة)ل،،1؛ ،٢٢ ع\\nساس.ساس\\nنبيد ءبد,ساح\\nص المسموح له مالكنالة وإبداء الراى فى الشاى العام\\nالمصرى وفى الظواهروالمشاكل والأزمات والوفانع الكونية\\nوالليمية المؤثرة عنى تفاصيل حباتها فى عالم الغرفة\\nالكونية او الاجهزة المحمولة متعددة الوسانعد\\nهل الساحة الصحفية -الغومية. . والاحرى وصفها يالسلطوة\\nمفتوحة امام جميع الصحفيين والكاب والخيرا، كى يشاركوا بإبدا،\\nآرانهم نبعا يلى حولهم لازثد على لسارات حماتهم البولبة لل وعلى\\nمصامرهم الجماعية أوم الغربية.؟\\nهل هناك معاييرموضوعية لاختيارمى الذى يكب ؤلماذا؟ هل الحرية\\nتعس ١لكلما له علانة مالصحابة يصلح للكامة المدتظعةوابا،الآرا،\\nفى نصابا وحوار ١لعامفىبلادتا؟\\nان عياب وحرمة والقيود المفروصة عليها هى مفتاح رئيس فى\\nالاحامة عى الاسنلة الساهغة. وس ثم بغال ان المسموج لهم هالكامة\\nهم المردس للسلطة الحاكمة او العدا صر المؤثرة نيها والغابرة عر\\nفرض مدا الكاتب او ذاك. واستبعاد معص الكتاب لانهم بحملش رزى\\nمغدية او رالبكالية لاحتاولش إشاعتها بين الفرا،) مغولة السلطوة\\nودلالاتها ند تكون مدخلا عاما لفهم حن الذى بتم اختيارهم للكابة ومن\\nينم امتدعادهم او إنصازهم عن التداخل نى الحدل العام وقضاياه\\nالرميسة. رش الحصير بى المشهد الكا بى رهين المواهغة أو الموالاة\\nلحطان السلطة السباسبة الحاكمة ومصالحها عر احتلاهها؟\\nثمة ترامط - مين السلطة ومصالحها وكابة الراى نى الصحف\\nلاسيما فى الدظم الشمولية والتملطية حيث لا يسدمم لأى أحد بان\\nيدخل إر دائرة ال'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 去除中文分割词\n",
    "takeaway_zh = [item.split(\"：\")[-1][1:] for item in extract_results]\n",
    "\n",
    "takeaway_zh[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bdd55f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4004 4238\n",
      "2014 2009\n",
      "2871 2871\n",
      "3074 3111\n",
      "4004 2407\n",
      "2548 2603\n",
      "3790 3879\n",
      "2144 2068\n",
      "2639 1977\n",
      "4004 3956\n"
     ]
    }
   ],
   "source": [
    "for eachone,polish in zip(small_batch, takeaway_zh):\n",
    "    eachone['polished'] = polish\n",
    "    print(len(eachone['context']), len(polish))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da32ee89",
   "metadata": {},
   "source": [
    "## Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8366dbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "292739578169461a9769cd9e82cec78c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f1d98f18b364fb396974007c4c4cff7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8493e508af694ab184f66d2a03742a2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "small_batch_dataset = Dataset.from_list(small_batch)\n",
    "\n",
    "small_batch_dataset.push_to_hub('small_batch_of_polishing_with_date_info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e987f078",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
