{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08a84a03",
   "metadata": {},
   "source": [
    "# Only take *Revolution* as probe\n",
    "\n",
    "## 1. Read data and select keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a96b182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'zh': '革命', 'ar': 'ثورة'}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kwpath = \"revo-related-keywords-select-by-freq.txt\"\n",
    "kwlist = []\n",
    "with open(kwpath, 'r', encoding='utf-8') as f:\n",
    "    kwlist = f.read().split('\\n')\n",
    "\n",
    "kwpairs = []\n",
    "for kwstr in kwlist:\n",
    "    kwstr = kwstr.strip().split('-')\n",
    "    kwpair = {\n",
    "        'zh':kwstr[1].strip(),\n",
    "        'ar':kwstr[0].strip()\n",
    "    }\n",
    "    kwpairs.append(kwpair)\n",
    "\n",
    "kwpairs = [kwpairs[0]]\n",
    "kwpairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcc1a981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to C:\\Users\\Chen Qun\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (C:/Users/Chen Qun/.cache/huggingface/datasets/Adelante___parquet/Adelante--Al-Ahram-raw-sliced-7fa24c1e217b75dc/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04259b30e3f34d7eabcf404c0dccd726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "from huggingface_hub import login\n",
    "\n",
    "# 输入你的 Hugging Face API token\n",
    "login('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')\n",
    "\n",
    "ds = load_dataset(\"Adelante/Al-Ahram-raw-sliced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b608e9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51292"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_num = len(ds['train'])\n",
    "text_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f204e0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contain_keyword(text):\n",
    "    flag = False\n",
    "    for kw in kwpairs:\n",
    "        if kw['ar'] in text:\n",
    "            flag = True\n",
    "            break\n",
    "    return flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfd60440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12619 / 51292 = 24.602277158231303 %\n"
     ]
    }
   ],
   "source": [
    "valid_cnt = 0\n",
    "\n",
    "sample = ds['train']['text']\n",
    "for text in sample:\n",
    "    if contain_keyword(text):\n",
    "        valid_cnt += 1\n",
    "# check ratio\n",
    "print(valid_cnt,'/', len(sample),'=',valid_cnt/len(sample)*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7acd406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['year', 'month', 'date', 'page', 'slice', 'text'],\n",
       "        num_rows: 51292\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a627bf47",
   "metadata": {},
   "source": [
    "## 2. Extract Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1783e224",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_contexts(example, keyword, context_size=4000):\n",
    "    text = example['text']\n",
    "    contexts = []\n",
    "    keyword_index = text.find(keyword)\n",
    "    \n",
    "    while keyword_index != -1:\n",
    "        start_index = max(0, keyword_index - context_size // 2)\n",
    "        end_index = min(len(text), keyword_index + len(keyword) + context_size // 2)\n",
    "        context = text[start_index:end_index]\n",
    "        contexts.append(context)\n",
    "        \n",
    "        # 从上次找到的位置后继续搜索\n",
    "        keyword_index = text.find(keyword, keyword_index + len(keyword))\n",
    "    \n",
    "    # 如果找到了上下文，则返回它们的列表；否则返回None\n",
    "    return {\n",
    "        'contexts': contexts if contexts else None\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7787f188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fb5affdd845413685048803fe7313e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51292 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "processed_dataset = ds['train'].map(lambda example: extract_contexts(example, kwpairs[0]['ar']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c0d0074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcfd11d3d77647ccb2dfd8b2a0eaffda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/51292 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['year', 'month', 'date', 'page', 'slice', 'text', 'contexts'],\n",
       "    num_rows: 12619\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 过滤掉 'contexts' 列为 None 的样本\n",
    "filtered_dataset = processed_dataset.filter(lambda example: example['contexts'] is not None)\n",
    "\n",
    "filtered_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ae247d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "746edf9199fb49b38afe34afc0f7cea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d662096859194f0bb7dc815d1f17c749",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/13 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e4d57a4d5da4b1b8bd197262eb5449c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75eda3a96df744d685d591a593da7a0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Deleting unused files from dataset repository:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ee2bcc987534db994e7062e884f648a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/382 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating downloaded metadata with the new split.\n"
     ]
    }
   ],
   "source": [
    "filtered_dataset.push_to_hub(\"revolution-as-kw-with-date-info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6554bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
