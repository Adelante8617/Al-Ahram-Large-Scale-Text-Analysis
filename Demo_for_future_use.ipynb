{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75829ccb",
   "metadata": {},
   "source": [
    "# Polish\n",
    "\n",
    "## prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dc043c",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\n",
    "# 读取你的提示词 或直接在此书写\n",
    "with open(\"prompt.txt\", 'r', encoding='utf-8') as f:\n",
    "    system_prompt += f.read()\n",
    "print(system_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b9b509",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e90ac16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取你希望处理的数据集\n",
    "\n",
    "dataset = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110d4286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['year', 'month', 'date', 'page', 'slice', 'text', 'containing'],\n",
       "        num_rows: 28240\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 运行该单元格以可视化部分结果\n",
    "# 例如，以huggingface的API读取的数据集可以输出它的每列属性\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed676f9a",
   "metadata": {},
   "source": [
    "## API\n",
    "\n",
    "调用LLM提供的API\n",
    "\n",
    "为加快调用速度，此处使用异步编程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b49ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import asyncio\n",
    "from datasets import load_dataset\n",
    "import json\n",
    "import openai\n",
    "from tqdm.asyncio import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974db507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 28240\n"
     ]
    }
   ],
   "source": [
    "# 选取一部分数据，此处使用全部\n",
    "\n",
    "small_batch = [dataset[idx] for idx in range(len(dataset))]\n",
    "print(type(small_batch), len(small_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ba81e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据供应商提供的接口调用\n",
    "# 参考： https://api-docs.deepseek.com/zh-cn/api/create-chat-completion\n",
    "BASE_URL = \"\"\n",
    "API_KEY = \"\"\n",
    "\n",
    "async def async_query_openai(query_message):\n",
    "    from openai import AsyncOpenAI\n",
    "    client = AsyncOpenAI(\n",
    "        base_url=BASE_URL,\n",
    "        api_key=API_KEY\n",
    "    )\n",
    "\n",
    "    \n",
    "    response = await client.chat.completions.create(\n",
    "        model=\"deepseek-chat\",\n",
    "        messages=[\n",
    "            {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": query_message \n",
    "            }\n",
    "        ],\n",
    "        # 以下参数可根据实际需求调整\n",
    "        max_tokens=4096,\n",
    "        temperature=0.01,\n",
    "        top_p=0.7,\n",
    "        # top_k=50,\n",
    "        frequency_penalty=1,\n",
    "        # stop=[\"<|eot_id|>\"],\n",
    "        stream=False\n",
    "    \n",
    "    )\n",
    "\n",
    "    if not response:\n",
    "        return 'null'\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "\n",
    "# 处理单个文本的函数\n",
    "async def process_text(text):\n",
    "    prompt = system_prompt + text\n",
    "    return await async_query_openai(prompt)\n",
    "\n",
    "# 将结果写入 .jsonl 文件的函数以保存结果\n",
    "def write_results_to_jsonl(rawtexts, results, filename):\n",
    "    with open(filename, 'a', encoding='utf-8') as f:  # 注意改为'a'模式，追加到文件中\n",
    "        for raw, result in zip(rawtexts, results):\n",
    "            entry = {\n",
    "                \"origin\":raw,\n",
    "                \"response\": result\n",
    "            }\n",
    "            json.dump(entry, f, ensure_ascii=False)\n",
    "            f.write('\\n')\n",
    "\n",
    "# 主函数，运行 asyncio 事件循环和写入结果\n",
    "async def main():\n",
    "    import nest_asyncio\n",
    "    nest_asyncio.apply()\n",
    "    batch_size = 500\n",
    "    for i in tqdm(range(0, len(small_batch), batch_size)):\n",
    "        current_batch = small_batch[i:i+batch_size]\n",
    "        print(f\"Processing batch {i // batch_size + 1}...\")\n",
    "        results = await process_all_texts(current_batch)\n",
    "        write_results_to_jsonl(current_batch, results, 'results.jsonl')\n",
    "        print(f\"Batch {i // batch_size + 1} written to results.jsonl\")\n",
    "        \n",
    "\n",
    "\n",
    "# 处理所有文本的函数，调整为处理一批文本\n",
    "async def process_all_texts(onebatch):\n",
    "    semaphore = asyncio.Semaphore(10000)\n",
    "    async def process_one_text(text):\n",
    "        async with semaphore:\n",
    "            return await process_text(text)\n",
    "    \n",
    "    tasks = []\n",
    "    for idx in range(len(onebatch)):\n",
    "        text = onebatch[idx]['text']\n",
    "        tasks.append(process_one_text(text))\n",
    "    results = await asyncio.gather(*tasks)  # 使用 gather 等待所有任务完成并保持顺序\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce134b56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 启动主函数\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f260329",
   "metadata": {},
   "source": [
    "## 输出结果\n",
    "\n",
    "读取输出的结果用于检查、后续处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ec336410",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    " \n",
    "file_jsonl_path = \"results.jsonl\"\n",
    "\n",
    "extract_results = []\n",
    "\n",
    "with open(file_jsonl_path, encoding='utf-8') as file:\n",
    "    for onetest in jsonlines.Reader(file):\n",
    "        extract_results.append(onetest['response'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
